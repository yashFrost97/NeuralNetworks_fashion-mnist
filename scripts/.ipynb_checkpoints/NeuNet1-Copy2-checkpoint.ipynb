{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "# Read Fashion MNIST dataset\n",
    "\n",
    "import util_mnist_reader\n",
    "X_train, y_train = util_mnist_reader.load_mnist('../data/fashion', kind='train')\n",
    "X_test, y_test = util_mnist_reader.load_mnist('../data/fashion', kind='t10k')\n",
    "\n",
    "# Your code goes here . . .\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights layer 1\n",
      "[[0.29613261 0.07394557 0.06761608 ... 0.78959852 0.32411739 0.68955547]\n",
      " [0.62679291 0.40693393 0.35047871 ... 0.57489535 0.69263887 0.55638506]\n",
      " [0.41376397 0.18313005 0.93473316 ... 0.10537718 0.88321796 0.67002759]\n",
      " ...\n",
      " [0.70682662 0.3472127  0.95574034 ... 0.56289918 0.9413945  0.3934421 ]\n",
      " [0.46391879 0.83474421 0.68579518 ... 0.73646562 0.08122014 0.62678815]\n",
      " [0.20637124 0.31803437 0.40655959 ... 0.39524871 0.56074552 0.07601515]]\n",
      "Initial Weights layer 2\n",
      "[[0.34365781 0.86458006 0.2506497  ... 0.66008817 0.94576422 0.39047251]\n",
      " [0.65890683 0.59506765 0.56760611 ... 0.39248712 0.36625627 0.06372305]\n",
      " [0.21464838 0.19096832 0.79868752 ... 0.46199565 0.79261829 0.09977647]\n",
      " ...\n",
      " [0.52113132 0.8558396  0.45639671 ... 0.15874106 0.34449178 0.26453034]\n",
      " [0.77437389 0.73214223 0.09094414 ... 0.49767712 0.40214734 0.51142105]\n",
      " [0.78017964 0.07298681 0.05442512 ... 0.48472037 0.54657931 0.24223243]]\n",
      "(784, 150)\n",
      "(150, 1)\n",
      "(150, 10)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# X_train = np.reshape(X_train, [60000, 28, 28])\n",
    "\n",
    "# initialize the values\n",
    "hidden_nodes = 150 # no of hidden nodes\n",
    "weight_l1 = np.random.rand(784, hidden_nodes)\n",
    "bias_l1 = np.random.rand(hidden_nodes, 1)\n",
    "\n",
    "print(\"Initial Weights layer 1\")\n",
    "print(weight_l1)\n",
    "\n",
    "\n",
    "weight_l2 = np.random.rand(hidden_nodes, 10)\n",
    "bias_l2 = np.random.rand(10, 1)\n",
    "\n",
    "print(\"Initial Weights layer 2\")\n",
    "print(weight_l2)\n",
    "\n",
    "\n",
    "losstrack = []\n",
    "training_errors = []\n",
    "test_wrong = []\n",
    "\n",
    "l_rate = 0.1\n",
    "epochs = 100\n",
    "\n",
    "print(weight_l1.shape)\n",
    "print(bias_l1.shape)\n",
    "\n",
    "print(weight_l2.shape)\n",
    "print(bias_l2.shape)\n",
    "\n",
    "def sigmoid(z):\n",
    "    ans = 1/(1 + np.exp(-z))\n",
    "    return ans\n",
    "\n",
    "def softmax(z):\n",
    "#     e_x = np.exp(z - np.max(z))\n",
    "#     return e_x / np.sum(e_x)\n",
    "#     z = z - z.max(axis = None, keepdims = True)\n",
    "#     y = np.exp(z)\n",
    "#     return y / y.sum(axis = None, keepdims = True)\n",
    "    temp = np.exp(z - np.max(z, axis = 1, keepdims = True))\n",
    "    return temp / np.sum(temp, axis = 1, keepdims = True)\n",
    "\n",
    "\n",
    "# def feed_forward():\n",
    "#     z_1 = np.dot(weights_l1.T, X_train) + bias_l1\n",
    "#     a_1 = sigmoid(z_1)\n",
    "#     z_2 = np.dot(weights_l2.T, a_1) + bias_l2\n",
    "#     a_2 = softmax(z_2)\n",
    "#     # return a_2\n",
    "\n",
    "# def sigmoid_prime(a):\n",
    "#     return np.dot(a, (1 - a).T)\n",
    "    \n",
    "# def feedbackward():\n",
    "#     dw_2 = np.dot(a_2 - y_train, a_1)\n",
    "#     w_2 = w_2 + dw_2\n",
    "#     a = sigmoid_prime(a_1)\n",
    "#     a = np.dot(a, X_train)\n",
    "#     dw_1 = np.dot(dw_2, a)\n",
    "#     dw_1 = w_1 + dw_1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_df = pd.DataFrame(y_train)\n",
    "\n",
    "# y_train_df = pd.get_dummies(y_train_df, )\n",
    "# y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(train, final):\n",
    "    loss = np.sum(-np.multiply(final, np.log(train + 1e-20)))\n",
    "    loss = loss / 60000\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 495.09449627612423\n",
      "epoch = 0\n",
      "loss = 495.09449799026896\n",
      "epoch = 1\n",
      "loss = 495.09449981194797\n",
      "epoch = 2\n",
      "loss = 495.09450173991127\n",
      "epoch = 3\n",
      "loss = 495.094503772923\n",
      "epoch = 4\n",
      "loss = 495.09450590976377\n",
      "epoch = 5\n",
      "loss = 495.0945081492265\n",
      "epoch = 6\n",
      "loss = 495.09451049011983\n",
      "epoch = 7\n",
      "loss = 495.09451293126614\n",
      "epoch = 8\n",
      "loss = 495.09451547150167\n",
      "epoch = 9\n",
      "loss = 495.094518109677\n",
      "epoch = 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-5c74f3924a8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mz_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_l1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbias_l1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0ma_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mz_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_l2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbias_l2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0ma_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-55-27ea98b60221>\u001b[0m in \u001b[0;36msigmoid\u001b[1;34m(z)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mans\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# np.set_printoptions(threshold = sys.maxsize)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    z_1 = np.dot(weight_l1.T, X_train.T) + bias_l1\n",
    "    a_1 = sigmoid(z_1)\n",
    "    z_2 = np.dot(weight_l2.T, a_1) + bias_l2\n",
    "    a_2 = softmax(z_2)\n",
    "    \n",
    "#     print(f\"a1 = shape {a_1.shape}\")\n",
    "#     print(f\"a2 = shape {a_2.shape}\")\n",
    "    \n",
    "    loss = cross_entropy(a_2, y_train)\n",
    "    losstrack.append(loss)\n",
    "    print(f\"loss = {loss}\")\n",
    "    \n",
    "    # back propagation starts here\n",
    "    error_y = (a_2 - y_train) / 60000.0\n",
    "    sigma_deri = np.multiply(a_1, np.subtract(1, a_1))\n",
    "#     print(f\"sigma deri shape = {sigma_deri.shape}\")\n",
    "#     print(f\"erro_y shape = {error_y.shape}\")\n",
    "    \n",
    "#     MY PART DONT TOUCH THIS TOO!!\n",
    "    part1 = np.dot(error_y.T, weight_l2.T)\n",
    "    dw_1 = np.multiply(part1, sigma_deri.T)\n",
    "    dw_1 = np.dot(dw_1.T, X_train)\n",
    "    dw_1 = dw_1.T\n",
    "    #print(dw_1.shape)\n",
    "    dw_2 = np.dot(error_y, a_1.T).T\n",
    "    #print(dw_2.shape)\n",
    "\n",
    "\n",
    "# DONT CHANGE THIS!!!!!!!!!\n",
    "#     dw_1 = np.dot(np.subtract(a_2, y_train.T).T/60000.0, weight_l2.T)\n",
    "#     #print(f\"1. {dw_1.shape}\")\n",
    "#     dw_1 = np.dot(dw_1.T, a_1.T)\n",
    "#     #print(f\"2. {dw_1.shape}\")\n",
    "#     dw_1 = np.dot(dw_1, (1 - a_1))\n",
    "#     #print(f\"3. {dw_1.shape}\")\n",
    "#     dw_1 = np.dot(dw_1, X_train)\n",
    "#     #print(f\"4. {dw_1.shape}\")\n",
    "    \n",
    "    \n",
    "#     dbias_1 = np.dot(error_y.T, weight_l2.T)\n",
    "#     dbias_1 = np.dot(dbias_1.T, sigma_deri.T)\n",
    "    #temp = (np.sum((np.multiply(np.dot(((a_2 - y_train.T)/60000).T, weight_l2.T).T, sigma_deri)), axis = 1)).reshape(hidden_nodes, 1)\n",
    "    \n",
    "    t1 = np.dot(((a_2 - y_train.T) / 60000).T, weight_l2.T).T\n",
    "    t2 = np.sum(np.multiply(t1, sigma_deri), axis = 1)\n",
    "    dbias_1 = t2.reshape(hidden_nodes, 1)\n",
    "    \n",
    "    dbias_2 = np.sum((a_2 - y_train.T)/60000, axis = 1).reshape(10, 1)\n",
    "#     print(f\"temp shape = {temp.shape}\")\n",
    "#     print(f\"db1 shape = {dbias_1.shape}\")\n",
    "#     print(f\"db2 shape = {dbias_2.shape}\")\n",
    "    \n",
    "    #weight_l1 = weight_l1 - l_rate * dw_1.T\n",
    "    weight_l1 = np.subtract(weight_l1, np.multiply(l_rate, dw_1))\n",
    "    weight_l2 = np.subtract(weight_l2, np.multiply(l_rate, dw_2))\n",
    "    bias_l1 = bias_l1 - l_rate * dbias_1\n",
    "    bias_l2 = bias_l2 - l_rate * dbias_2\n",
    "    \n",
    "    print(f\"epoch = {epoch}\")\n",
    "\n",
    "print(\"Weights layer 1 : \")\n",
    "print(weight_l1)\n",
    "\n",
    "print(\"Weights layer 2 : \")\n",
    "print(weight_l2)\n",
    "\n",
    "plt.plot(losstrack)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_1\n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "(150, 60000)\n",
      "a_2\n",
      "[[1.03770413e-05 1.03770413e-05 1.03770413e-05 ... 1.03770413e-05\n",
      "  1.03770413e-05 1.03770413e-05]\n",
      " [2.30414177e-09 2.30414177e-09 2.30414177e-09 ... 2.30414177e-09\n",
      "  2.30414177e-09 2.30414177e-09]\n",
      " [1.34708829e-08 1.34708829e-08 1.34708829e-08 ... 1.34708829e-08\n",
      "  1.34708829e-08 1.34708829e-08]\n",
      " ...\n",
      " [3.85081841e-06 3.85081841e-06 3.85081841e-06 ... 3.85081841e-06\n",
      "  3.85081841e-06 3.85081841e-06]\n",
      " [7.54443991e-10 7.54443991e-10 7.54443991e-10 ... 7.54443991e-10\n",
      "  7.54443991e-10 7.54443991e-10]\n",
      " [1.64320758e-10 1.64320758e-10 1.64320758e-10 ... 1.64320758e-10\n",
      "  1.64320758e-10 1.64320758e-10]]\n",
      "(10, 60000)\n",
      "dw_1\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-1.00892083e-13 -7.41582297e-14 -2.30885117e-13 ... -3.99945975e-14\n",
      "  -2.18200442e-13 -9.09792461e-14]\n",
      " [-1.01006165e-13 -7.41827587e-14 -2.30899627e-13 ... -4.00083260e-14\n",
      "  -2.18221630e-13 -9.10557328e-14]\n",
      " ...\n",
      " [-1.41299483e-11 -1.47391532e-11 -1.57231755e-11 ... -8.59924302e-12\n",
      "  -6.15249255e-12 -4.84561636e-11]\n",
      " [-4.78737526e-13 -2.24277278e-12 -1.44805327e-12 ... -4.25040163e-12\n",
      "  -1.64574319e-12 -9.49256505e-12]\n",
      " [-2.92671836e-14 -8.61393299e-14 -5.53013623e-14 ... -2.44985021e-13\n",
      "  -6.10626039e-14 -3.35655743e-13]]\n",
      "dw_2\n",
      "[[-4.49998959 -4.49999996 -4.49999995 ... -4.49999611 -4.49999996\n",
      "  -4.49999996]\n",
      " [-4.49998956 -4.49999994 -4.49999993 ... -4.49999609 -4.49999994\n",
      "  -4.49999994]\n",
      " [-4.4999896  -4.49999997 -4.49999996 ... -4.49999612 -4.49999997\n",
      "  -4.49999997]\n",
      " ...\n",
      " [-4.4999896  -4.49999997 -4.49999996 ... -4.49999613 -4.49999998\n",
      "  -4.49999998]\n",
      " [-4.49998959 -4.49999997 -4.49999996 ... -4.49999612 -4.49999997\n",
      "  -4.49999997]\n",
      " [-4.49998959 -4.49999996 -4.49999995 ... -4.49999612 -4.49999997\n",
      "  -4.49999997]]\n",
      "z_2\n",
      "[[34022.41928602 34022.41928602 34022.41928602 ... 34022.41928602\n",
      "  34022.41928602 34022.41928601]\n",
      " [34014.00664321 34014.00664321 34014.00664321 ... 34014.00664321\n",
      "  34014.00664321 34014.00664321]\n",
      " [34015.77246547 34015.77246547 34015.77246547 ... 34015.77246547\n",
      "  34015.77246547 34015.77246547]\n",
      " ...\n",
      " [34021.42797591 34021.42797591 34021.42797591 ... 34021.42797591\n",
      "  34021.42797591 34021.42797591]\n",
      " [34012.8901607  34012.8901607  34012.8901607  ... 34012.8901607\n",
      "  34012.8901607  34012.8901607 ]\n",
      " [34011.36600001 34011.36600001 34011.36600001 ... 34011.36600001\n",
      "  34011.36600001 34011.36600001]]\n"
     ]
    }
   ],
   "source": [
    "print(\"a_1\")\n",
    "print(a_1)\n",
    "print(a_1.shape)\n",
    "\n",
    "print(\"a_2\")\n",
    "print(a_2)\n",
    "print(a_2.shape)\n",
    "print(\"dw_1\")\n",
    "print(dw_1)\n",
    "\n",
    "print(\"dw_2\")\n",
    "print(dw_2)\n",
    "\n",
    "print(\"z_2\")\n",
    "print(z_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "[1 1 1 ... 1 1 1]\n",
      "accuracy = 0.1\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "train_output = []\n",
    "for i in range(len(y_train)):\n",
    "    max = 0\n",
    "    k = 0\n",
    "    for j in range(10):\n",
    "        if(a_2[j][i] > max):\n",
    "            max = a_2[j][i]\n",
    "            k = j\n",
    "    train_output.append(k)\n",
    "    \n",
    "train_output = np.array(train_output)\n",
    "print(train_output.shape)\n",
    "\n",
    "equals = 0\n",
    "for i in range(len(y_train)):\n",
    "    if(y_train[i] == int(train_output[i])):\n",
    "        equals += 1\n",
    "        \n",
    "acc = equals/len(y_train)\n",
    "print(train_output)\n",
    "print(f\"accuracy = {acc}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.13690215e-07 1.13690215e-07 1.13690215e-07 ... 1.13690215e-07\n",
      "  1.13690215e-07 1.13690215e-07]\n",
      " [6.41818207e-06 6.41818207e-06 6.41818207e-06 ... 6.41818207e-06\n",
      "  6.41818207e-06 6.41818207e-06]\n",
      " [1.68956776e-06 1.68956776e-06 1.68956776e-06 ... 1.68956776e-06\n",
      "  1.68956776e-06 1.68956776e-06]\n",
      " ...\n",
      " [2.85564236e-07 2.85564236e-07 2.85564236e-07 ... 2.85564236e-07\n",
      "  2.85564236e-07 2.85564236e-07]\n",
      " [1.47203239e-07 1.47203239e-07 1.47203239e-07 ... 1.47203239e-07\n",
      "  1.47203239e-07 1.47203239e-07]\n",
      " [9.43013345e-07 9.43013345e-07 9.43013345e-07 ... 9.43013345e-07\n",
      "  9.43013345e-07 9.43013345e-07]]\n"
     ]
    }
   ],
   "source": [
    "z_1 = np.dot(weight_l1.T, X_test.T) + bias_l1\n",
    "a_1 = sigmoid(z_1)\n",
    "z_2 = np.dot(weight_l2.T, a_1) + bias_l2\n",
    "a_2 = softmax(z_2)\n",
    "\n",
    "print(a_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "[6 6 6 ... 6 6 6]\n",
      "accuracy = 0.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_output = []\n",
    "# import sys\n",
    "# np.set_printoptions(threshold = sys.maxsize)\n",
    "for i in range(len(y_test)):\n",
    "    max = 0\n",
    "    k = 0\n",
    "    for j in range(10):\n",
    "        if(a_2[j][i] > max):\n",
    "            max = a_2[j][i]\n",
    "            k = j\n",
    "    test_output.append(k)\n",
    "    \n",
    "test_output = np.array(test_output)\n",
    "print(test_output.shape)\n",
    "\n",
    "equals = 0\n",
    "for i in range(len(y_test)):\n",
    "    if(y_test[i] == int(test_output[i])):\n",
    "        equals += 1\n",
    "        \n",
    "acc = equals/len(y_test)\n",
    "print(test_output)\n",
    "print(f\"accuracy = {acc}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
